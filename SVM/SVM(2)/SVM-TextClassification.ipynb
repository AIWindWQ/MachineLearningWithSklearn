{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 垃圾短信分类\n",
    "语料是短信消息，分为两类，分别是正常的短信，如祝福消息、验证码消息等一些有用消息，标签为0；另一类是垃圾消息，如广告、推销等垃圾信息，标签为1。且标签与文本内容之间使用'\\t'分开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入相关的包\n",
    "import jieba\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "def read_data(data_path):\n",
    "    \"\"\"\n",
    "    读取数据\n",
    "    :param data_path: 数据存放路径\n",
    "    :return: 读取到的数据\n",
    "    \"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分词并划分数据集\n",
    "def cut_words(data, stopwords, test_size=0.2):\n",
    "    \"\"\"\n",
    "    分词、去停用词并将数据集分成训练集和测试集\n",
    "    :param data: 文本数据\n",
    "    :param stopwords: 停用词\n",
    "    :param test_size: 测试集和训练集的划分比例\n",
    "    :return: 测试集和训练集\n",
    "    \"\"\"\n",
    "    stop_words = list()\n",
    "    for word in stopwords:\n",
    "        stop_words.append(word[:-1])\n",
    "    y = list()\n",
    "    text_list = list()\n",
    "    for line in data:\n",
    "        label, text = line.split('\\t', 1)\n",
    "        cut_text = [word for word in jieba.cut(text) if word not in stop_words]\n",
    "        if cut_text == '':\n",
    "            continue\n",
    "        else:\n",
    "            text_list.append(' '.join(cut_text))\n",
    "            y.append(int(label))\n",
    "    return sklearn.model_selection.train_test_split(text_list, y, test_size=test_size, random_state=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数据集计算tfidf向量\n",
    "def calculate_tfidf(X_train, X_test):\n",
    "    \"\"\"\n",
    "    计算文本的tf-idf\n",
    "    :param X_train: 训练集\n",
    "    :param X_test: 测试集\n",
    "    :return: 返回的是文本的tf-idf特征\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit_transform(X_train)\n",
    "    X_train_tfidf = vectorizer.transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    return X_train_tfidf, X_test_tfidf, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型评估\n",
    "def evaluate(model, X, y):\n",
    "    \"\"\"\n",
    "    模型评估\n",
    "    :param model: 训练好的模型\n",
    "    :param X: 测试集\n",
    "    :param y: 测试集标签\n",
    "    :return: 正确率和auc值\n",
    "    \"\"\"\n",
    "    accuracy = model.score(X, y)\n",
    "    a = model.predict_proba(X)[:, 1]\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y, model.predict_proba(X)[:, 1], pos_label=1)\n",
    "    return accuracy, sklearn.metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下过程进行文本分类建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1 读取数据（文本和停用词）\n",
    "data_path = \"./data/train.txt\"\n",
    "stopwords_path = \"./data/stopwords.txt\"\n",
    "data = read_data(data_path)\n",
    "stopwords = read_data(stopwords_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\MSWQPC\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.498 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# step2 分词、分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = cut_words(data, stopwords, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3 提取特征参数（tf-idf），得到特征向量\n",
    "X_train_tfidf, X_test_tfidf, tfidf_model = calculate_tfidf(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step4 训练模型\n",
    "svm = SVC(C=1.0, probability=True)\n",
    "svm.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集正确率：99.7136%\n",
      "\n",
      "训练集AUC值：0.999424\n",
      "\n",
      "测试集正确率：94.6841%\n",
      "\n",
      "测试AUC值：0.988868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step5 模型评估\n",
    "accuracy, auc = evaluate(svm, X_train_tfidf, y_train)\n",
    "print(\"训练集正确率：%.4f%%\\n\" % (accuracy * 100))\n",
    "print(\"训练集AUC值：%.6f\\n\" % auc)\n",
    "\n",
    "accuracy, auc = evaluate(svm, X_test_tfidf, y_test)\n",
    "print(\"测试集正确率：%.4f%%\\n\" % (accuracy * 100))\n",
    "print(\"测试AUC值：%.6f\\n\" % auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
