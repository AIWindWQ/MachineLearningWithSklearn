{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 垃圾短信分类\n",
    "语料是短信消息，分为两类，分别是正常的短信，如祝福消息、验证码消息等一些有用消息，标签为0；另一类是垃圾消息，如广告、推销等垃圾信息，标签为1。且标签与文本内容之间使用'\\t'分开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer      #使用Tfidf进行文本的向量化处理，提取文本特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    \"\"\"\n",
    "    读取数据\n",
    "    :param data_path: 数据存放路径\n",
    "    :return: 读取到的数据\n",
    "    \"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_words(data,stopwords, test_size=0.3):\n",
    "    \"\"\"\n",
    "    分词、去停用词并将数据集分成训练集和测试集\n",
    "    :param data: 文本数据\n",
    "    :param stopwords: 停用词\n",
    "    :param test_size: 测试集的比例\n",
    "    :return: 测试集和训练集\n",
    "    \"\"\"\n",
    "    stop_words = list()\n",
    "    for word in stopwords:\n",
    "        stop_words.append(word[:-1])\n",
    "    y = list()\n",
    "    text_list = list()\n",
    "    for line in data:\n",
    "        label, text = line.split('\\t', 1)     #num=1，表示分割1次，返回两个列表，分别为label和text\n",
    "        cut_text = [word for word in jieba.cut(text) if word not in stop_words]\n",
    "        if cut_text == '':\n",
    "            continue\n",
    "        else:\n",
    "            text_list.append(' '.join(cut_text))\n",
    "            y.append(int(label))\n",
    "    return sklearn.model_selection.train_test_split(text_list, y, test_size=test_size, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tfidf(X_train, X_test):\n",
    "    \"\"\"\n",
    "    计算文本的tf-idf\n",
    "    :param X_train: 训练集\n",
    "    :param X_test: 测试集\n",
    "    :return: 返回的是文本的tf-idf特征向量\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit_transform(X_train)\n",
    "    X_train_tfidf = vectorizer.transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    return X_train_tfidf, X_test_tfidf, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y):\n",
    "    \"\"\"\n",
    "    模型评估\n",
    "    :param model: 训练好的模型\n",
    "    :param X: 测试集\n",
    "    :param y: 测试集标签\n",
    "    :return: 正确率和auc值\n",
    "    \"\"\"\n",
    "    accuracy = model.score(X, y)\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y, model.predict_proba(X)[:, 1], pos_label=1)\n",
    "    return accuracy, sklearn.metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下为文本分类建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1 读取数据（文本和停用词）\n",
    "data_path = \"./data/train.txt\"\n",
    "stopwords_path = \"./data/stopwords.txt\"\n",
    "data = read_data(data_path)\n",
    "stopwords = read_data(stopwords_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\MSWQPC\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.395 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# step2 分词、分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = cut_words(data, stopwords, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3 提取特征参数（tf-idf）\n",
    "X_train_tfidf, X_test_tfidf, tfidf_model = calculate_tfidf(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step4 训练lr模型\n",
    "lr = LogisticRegression(C=0.5)\n",
    "lr.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集正确率：92.7223%\n",
      "\n",
      "训练集AUC值：0.993224\n",
      "\n",
      "测试集正确率：90.9174%\n",
      "\n",
      "测试AUC值：0.980725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step5 模型评估\n",
    "accuracy, auc = evaluate(lr, X_train_tfidf, y_train)\n",
    "print(\"训练集正确率：%.4f%%\\n\" % (accuracy * 100))\n",
    "print(\"训练集AUC值：%.6f\\n\" % auc)\n",
    "\n",
    "accuracy, auc = evaluate(lr, X_test_tfidf, y_test)\n",
    "print(\"测试集正确率：%.4f%%\\n\" % (accuracy * 100))\n",
    "print(\"测试AUC值：%.6f\\n\" % auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
